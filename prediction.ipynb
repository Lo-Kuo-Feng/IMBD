{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已載入 0 個模型，還剩 47 個模型待載入\n",
      "已載入 1 個模型，還剩 46 個模型待載入\n",
      "已載入 2 個模型，還剩 45 個模型待載入\n",
      "已載入 3 個模型，還剩 44 個模型待載入\n",
      "已載入 4 個模型，還剩 43 個模型待載入\n",
      "已載入 5 個模型，還剩 42 個模型待載入\n",
      "已載入 6 個模型，還剩 41 個模型待載入\n",
      "已載入 7 個模型，還剩 40 個模型待載入\n",
      "已載入 8 個模型，還剩 39 個模型待載入\n",
      "已載入 9 個模型，還剩 38 個模型待載入\n",
      "已載入 10 個模型，還剩 37 個模型待載入\n",
      "已載入 11 個模型，還剩 36 個模型待載入\n",
      "已載入 12 個模型，還剩 35 個模型待載入\n",
      "已載入 13 個模型，還剩 34 個模型待載入\n",
      "已載入 14 個模型，還剩 33 個模型待載入\n",
      "已載入 15 個模型，還剩 32 個模型待載入\n",
      "已載入 16 個模型，還剩 31 個模型待載入\n",
      "已載入 17 個模型，還剩 30 個模型待載入\n",
      "已載入 18 個模型，還剩 29 個模型待載入\n",
      "已載入 19 個模型，還剩 28 個模型待載入\n",
      "已載入 20 個模型，還剩 27 個模型待載入\n",
      "已載入 21 個模型，還剩 26 個模型待載入\n",
      "已載入 22 個模型，還剩 25 個模型待載入\n",
      "已載入 23 個模型，還剩 24 個模型待載入\n",
      "已載入 24 個模型，還剩 23 個模型待載入\n",
      "已載入 25 個模型，還剩 22 個模型待載入\n",
      "已載入 26 個模型，還剩 21 個模型待載入\n",
      "已載入 27 個模型，還剩 20 個模型待載入\n",
      "已載入 28 個模型，還剩 19 個模型待載入\n",
      "已載入 29 個模型，還剩 18 個模型待載入\n",
      "已載入 30 個模型，還剩 17 個模型待載入\n",
      "已載入 31 個模型，還剩 16 個模型待載入\n",
      "已載入 32 個模型，還剩 15 個模型待載入\n",
      "已載入 33 個模型，還剩 14 個模型待載入\n",
      "已載入 34 個模型，還剩 13 個模型待載入\n",
      "已載入 35 個模型，還剩 12 個模型待載入\n",
      "已載入 36 個模型，還剩 11 個模型待載入\n",
      "已載入 37 個模型，還剩 10 個模型待載入\n",
      "已載入 38 個模型，還剩 9 個模型待載入\n",
      "已載入 39 個模型，還剩 8 個模型待載入\n",
      "已載入 40 個模型，還剩 7 個模型待載入\n",
      "已載入 41 個模型，還剩 6 個模型待載入\n",
      "已載入 42 個模型，還剩 5 個模型待載入\n",
      "已載入 43 個模型，還剩 4 個模型待載入\n",
      "已載入 44 個模型，還剩 3 個模型待載入\n",
      "已載入 45 個模型，還剩 2 個模型待載入\n",
      "已載入 46 個模型，還剩 1 個模型待載入\n",
      "模型載入完畢\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_data(path=None):\n",
    "    \"\"\"獲取數據的函數,輸入路徑型式為字串,回傳數據型式為numpy.ndarray\"\"\"\n",
    "    import numpy as np\n",
    "    f = open(path)\n",
    "    text = []\n",
    "    for line in f:\n",
    "        text.append(line)\n",
    "    data = []                                  \n",
    "    for i in range(len([eval(s.strip()) for s in text[-1].split(\"\\t\")[:-1]])):\n",
    "        d = []\n",
    "        for j in range(2, len(text)):\n",
    "            d.append([eval(s.strip()) for s in text[j].split(\"\\t\")[:-1]][i])\n",
    "        data.append(d)   \n",
    "    return np.array(data)\n",
    "\n",
    "def get_dataname(path=None):\n",
    "    \"\"\"獲取數據的函數,輸入路徑型式為字串,回傳數據型式為list\"\"\"\n",
    "    import numpy as np\n",
    "    f = open(path)\n",
    "    text = []\n",
    "    for line in f:\n",
    "        text.append(line)\n",
    "    dataname = [ path+\"-\"+str(i) for i in range(len(text[2].split(\"\\t\")[:-1]))]\n",
    "    return dataname\n",
    "\n",
    "def pretreatment(data=None):\n",
    "    \"\"\"預處理函數,功能為raw data,輸入數據型式為numpy.ndarray,回傳數據型式為numpy.ndarray\"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    new_data = np.where(data==0,None,data)\n",
    "    return np.pad(new_data, (0, 0), 'edge') #(0, length-dl)為前後補齊數量\n",
    "\n",
    "def class_data(txt=None):\n",
    "    \"\"\"取得同一資料夾數據,回傳數據型式為list\"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    data = []\n",
    "    dataname = []\n",
    "    d = get_data(txt)\n",
    "    dn = get_dataname(txt)\n",
    "    for i in range(len(d)):\n",
    "        data.append(pretreatment(d[i]))\n",
    "    dataname.extend(dn)\n",
    "    return data, dataname\n",
    "\n",
    "def predict(model=None, path=None, IMG_HEIGHT=None, IMG_WEIGHT=None):\n",
    "    \"\"\"讀取圖片預測類別\"\"\"\n",
    "    import numpy as np\n",
    "    from PIL import Image   \n",
    "    label_dict = {0: 'G11', 1: 'G15', 2: 'G17', 3: 'G19', 4: 'G32', 5: 'G34', 6: 'G48', 7: 'G49'}\n",
    "    img_data = np.ndarray((1,IMG_HEIGHT , IMG_WEIGHT, 3), dtype=np.uint8)\n",
    "    img = Image.open(path) \n",
    "    img = img.resize((IMG_HEIGHT , IMG_WEIGHT), Image.BILINEAR)\n",
    "    img_data[0] = img\n",
    "    img_data = img_data/ 255\n",
    "    return label_dict[model.predict_classes(img_data)[0]]\n",
    "\n",
    "model_list = []\n",
    "for i, model_name in enumerate(glob.glob(os.path.join(\"model\",r\"*50*.hd5\"))):\n",
    "    print(\"已載入\", i, \"個模型，還剩\", len(glob.glob(os.path.join(\"model\",r\"*50*.hd5\")))-i, \"個模型待載入\")\n",
    "    model_list.append(load_model(model_name))\n",
    "print(\"模型載入完畢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt \t預測類別為 => G11\n",
      "2.txt \t預測類別為 => G11\n",
      "3.txt \t預測類別為 => G15\n",
      "4.txt \t預測類別為 => G15\n",
      "5.txt \t預測類別為 => G15\n",
      "6.txt \t預測類別為 => G15\n",
      "7.txt \t預測類別為 => G15\n",
      "8.txt \t預測類別為 => G15\n",
      "9.txt \t預測類別為 => G17\n",
      "10.txt \t預測類別為 => G17\n",
      "11.txt \t預測類別為 => G19\n",
      "12.txt \t預測類別為 => G19\n",
      "13.txt \t預測類別為 => G32\n",
      "14.txt \t預測類別為 => G32\n",
      "15.txt \t預測類別為 => G32\n",
      "16.txt \t預測類別為 => G32\n",
      "17.txt \t預測類別為 => G32\n",
      "18.txt \t預測類別為 => G32\n",
      "19.txt \t預測類別為 => G34\n",
      "20.txt \t預測類別為 => G34\n",
      "21.txt \t預測類別為 => G34\n",
      "22.txt \t預測類別為 => G34\n",
      "23.txt \t預測類別為 => G34\n",
      "24.txt \t預測類別為 => G34\n",
      "25.txt \t預測類別為 => G48\n",
      "26.txt \t預測類別為 => G48\n",
      "27.txt \t預測類別為 => G48\n",
      "28.txt \t預測類別為 => G48\n",
      "29.txt \t預測類別為 => G48\n",
      "30.txt \t預測類別為 => G48\n",
      "31.txt \t預測類別為 => G49\n",
      "32.txt \t預測類別為 => G49\n",
      "33.txt \t預測類別為 => G49\n",
      "34.txt \t預測類別為 => G49\n",
      "35.txt \t預測類別為 => G49\n",
      "36.txt \t預測類別為 => G49\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for i in os.listdir(\"data\"):\n",
    "    if i.endswith('.txt'):\n",
    "        data_list.append(int(i.split(\".txt\")[0]))\n",
    "data_list.sort()\n",
    "\n",
    "data_list_name = []\n",
    "for i in data_list:\n",
    "    data_list_name.append(str(i)+\".txt\")\n",
    "\n",
    "image_size = 50\n",
    "df = pd.read_excel(\"108064_TestResult.xlsx\")\n",
    "n = 0\n",
    "for name in data_list_name:\n",
    "    data, dataname = class_data(os.path.join(\"data\",name))\n",
    "\n",
    "    folder = \"data image\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    for i, j in enumerate(data):  \n",
    "        plt.plot(j)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(folder,dataname[i].split(\"\\\\\")[1].split(\".txt\")[0]+dataname[i].split(\"\\\\\")[1].split(\".txt\")[1])+\".jpg\")\n",
    "        plt.close('all')\n",
    "        \n",
    "    \n",
    "    prediction_category = ([[]])\n",
    "\n",
    "    for img in os.listdir(folder):\n",
    "        prediction_array = np.array([[]])\n",
    "        for model in model_list:  \n",
    "            prediction_array = np.append(prediction_array, predict(model=model, path=os.path.join(folder,img), IMG_HEIGHT=image_size, IMG_WEIGHT=image_size))\n",
    "        vals, counts = np.unique(prediction_array, return_counts=True) \n",
    "   \n",
    "\n",
    "        prediction_category = np.append(prediction_category, vals[np.argmax(counts)])\n",
    "    \n",
    "    shutil.rmtree(\"data image\")\n",
    "    vals, counts = np.unique(prediction_category, return_counts=True)\n",
    "    print(name,\"\\t預測類別為 =>\", vals[np.argmax(counts)])\n",
    "    \n",
    "    df.loc[n, \"分類結果\"] = vals[np.argmax(counts)]\n",
    "    n += 1\n",
    "df.to_excel('108064_TestResult.xlsx',sheet_name='工作表1',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
